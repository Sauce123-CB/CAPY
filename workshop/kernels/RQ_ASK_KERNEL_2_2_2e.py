"""
RQ_ASK_KERNEL_2_2_2e.py
CAPY Pipeline - Research Question Execution via Gemini Deep Research

This kernel executes the 6 Research Questions generated by RQ_GEN using
Google Gemini Deep Research (GDR) for comprehensive web synthesis.

Authentication Strategy:
- Primary: OAuth via Gemini CLI (~/.gemini/ credentials)
- Fallback: GEMINI_API_KEY from environment

Usage:
    from RQ_ASK_KERNEL_2_2_2e import execute_research_plan

    results = await execute_research_plan(
        research_plan=a8_research_strategy_map,
        ticker="DAVE",
        max_concurrent=3
    )
"""

import asyncio
import json
import os
import subprocess
import tempfile
import logging
from datetime import datetime
from pathlib import Path
from typing import Optional
from dataclasses import dataclass, field, asdict

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("RQ_ASK")

# ============================================================================
# CONFIGURATION
# ============================================================================

# Deep Research model - updated Dec 2025
# Note: "gemini-2.0-flash-thinking-exp" was deprecated
# Using gemini-2.5-pro which supports web search grounding
DEEP_RESEARCH_MODEL = "gemini-2.5-pro"

# Gemini CLI path (set by npm global install)
GEMINI_CLI_PATH = os.path.expanduser("~/.npm-global/bin/gemini")

# Max concurrent queries (platform limit)
MAX_CONCURRENT = 6

# Query timeout (Deep Research can take 2-5 minutes per query)
QUERY_TIMEOUT_SECONDS = 600

# ============================================================================
# DATA STRUCTURES
# ============================================================================

@dataclass
class ResearchQuery:
    """Single research query from A.8 Research Plan."""
    rq_id: str
    allocation_type: str  # MANDATORY | DYNAMIC
    coverage_objective: str  # M-1/M-2/M-3 or Lynchpin ID
    platform: str  # GDR (all queries now route to GDR)
    platform_rationale: str
    a7_linkage: str
    prompt_text: str


@dataclass
class ResearchResult:
    """Result from a single Deep Research query."""
    rq_id: str
    status: str  # SUCCESS | ERROR | TIMEOUT
    query_text: str
    response_text: str
    sources: list = field(default_factory=list)
    execution_time_seconds: float = 0.0
    timestamp: str = ""
    error_message: Optional[str] = None

    def to_dict(self):
        return asdict(self)


@dataclass
class ResearchPlanResults:
    """Complete results from executing the research plan."""
    ticker: str
    execution_timestamp: str
    total_queries: int
    successful_queries: int
    failed_queries: int
    results: list
    execution_time_seconds: float

    def to_dict(self):
        d = asdict(self)
        d['results'] = [r.to_dict() if hasattr(r, 'to_dict') else r for r in self.results]
        return d


# ============================================================================
# GEMINI DEEP RESEARCH EXECUTION
# ============================================================================

async def execute_deep_research_cli(query: ResearchQuery) -> ResearchResult:
    """
    Execute a Deep Research query using Gemini CLI.

    The CLI handles OAuth authentication automatically using cached credentials.
    """
    start_time = datetime.now()
    logger.info(f"[{query.rq_id}] Starting Deep Research query...")

    try:
        # Create temp file for the query
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write(query.prompt_text)
            query_file = f.name

        # Build command - pipe query through stdin
        cmd = [
            GEMINI_CLI_PATH,
            "-m", DEEP_RESEARCH_MODEL,
            "-p", query.prompt_text
        ]

        # Execute with timeout
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        try:
            stdout, stderr = await asyncio.wait_for(
                process.communicate(),
                timeout=QUERY_TIMEOUT_SECONDS
            )
        except asyncio.TimeoutError:
            process.kill()
            await process.wait()
            os.unlink(query_file)

            return ResearchResult(
                rq_id=query.rq_id,
                status="TIMEOUT",
                query_text=query.prompt_text,
                response_text="",
                execution_time_seconds=(datetime.now() - start_time).total_seconds(),
                timestamp=datetime.now().isoformat(),
                error_message=f"Query timed out after {QUERY_TIMEOUT_SECONDS}s"
            )

        os.unlink(query_file)

        if process.returncode != 0:
            error_msg = stderr.decode() if stderr else "Unknown error"
            logger.error(f"[{query.rq_id}] CLI error: {error_msg}")

            return ResearchResult(
                rq_id=query.rq_id,
                status="ERROR",
                query_text=query.prompt_text,
                response_text="",
                execution_time_seconds=(datetime.now() - start_time).total_seconds(),
                timestamp=datetime.now().isoformat(),
                error_message=error_msg
            )

        response_text = stdout.decode()
        execution_time = (datetime.now() - start_time).total_seconds()

        logger.info(f"[{query.rq_id}] Completed in {execution_time:.1f}s")

        return ResearchResult(
            rq_id=query.rq_id,
            status="SUCCESS",
            query_text=query.prompt_text,
            response_text=response_text,
            sources=[],  # TODO: Parse sources from response if available
            execution_time_seconds=execution_time,
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        logger.exception(f"[{query.rq_id}] Unexpected error")
        return ResearchResult(
            rq_id=query.rq_id,
            status="ERROR",
            query_text=query.prompt_text,
            response_text="",
            execution_time_seconds=(datetime.now() - start_time).total_seconds(),
            timestamp=datetime.now().isoformat(),
            error_message=str(e)
        )


async def execute_deep_research_sdk(query: ResearchQuery) -> ResearchResult:
    """
    Execute a Deep Research query using google-genai SDK.

    Requires GEMINI_API_KEY environment variable.
    Note: SDK v1.47.0 may not have Interactions API for true Deep Research.
    Falls back to standard generation.
    """
    start_time = datetime.now()
    logger.info(f"[{query.rq_id}] Starting SDK query...")

    try:
        from google import genai

        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY not found in environment")

        client = genai.Client(api_key=api_key)

        # Standard generation (not Deep Research)
        response = client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=query.prompt_text
        )

        execution_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"[{query.rq_id}] Completed in {execution_time:.1f}s")

        return ResearchResult(
            rq_id=query.rq_id,
            status="SUCCESS",
            query_text=query.prompt_text,
            response_text=response.text,
            sources=[],
            execution_time_seconds=execution_time,
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        logger.exception(f"[{query.rq_id}] SDK error")
        return ResearchResult(
            rq_id=query.rq_id,
            status="ERROR",
            query_text=query.prompt_text,
            response_text="",
            execution_time_seconds=(datetime.now() - start_time).total_seconds(),
            timestamp=datetime.now().isoformat(),
            error_message=str(e)
        )


# ============================================================================
# MAIN EXECUTION
# ============================================================================

async def execute_research_plan(
    research_plan: dict,
    ticker: str,
    max_concurrent: int = MAX_CONCURRENT,
    use_cli: bool = True
) -> ResearchPlanResults:
    """
    Execute the full research plan from A.8_RESEARCH_STRATEGY_MAP.

    Args:
        research_plan: The A.8 artifact from RQ_GEN
        ticker: Company ticker symbol
        max_concurrent: Maximum concurrent queries (default 6)
        use_cli: Use Gemini CLI (True) or SDK (False)

    Returns:
        ResearchPlanResults with all query results
    """
    start_time = datetime.now()

    # Parse research plan
    rq_list = research_plan.get("Research_Plan", [])
    if not rq_list:
        raise ValueError("Research_Plan is empty")

    queries = [
        ResearchQuery(
            rq_id=rq["RQ_ID"],
            allocation_type=rq.get("Allocation_Type", "DYNAMIC"),
            coverage_objective=rq.get("Coverage_Objective", ""),
            platform=rq.get("Platform", "GDR"),
            platform_rationale=rq.get("Platform_Rationale", ""),
            a7_linkage=rq.get("A7_Linkage", ""),
            prompt_text=rq["Prompt_Text"]
        )
        for rq in rq_list
    ]

    logger.info(f"Executing {len(queries)} research queries for {ticker}")
    logger.info(f"Max concurrent: {max_concurrent}, Using: {'CLI' if use_cli else 'SDK'}")

    # Select execution function
    execute_fn = execute_deep_research_cli if use_cli else execute_deep_research_sdk

    # Execute with semaphore for concurrency control
    semaphore = asyncio.Semaphore(max_concurrent)

    async def execute_with_semaphore(query: ResearchQuery) -> ResearchResult:
        async with semaphore:
            return await execute_fn(query)

    # Run all queries concurrently (up to max_concurrent at a time)
    results = await asyncio.gather(
        *[execute_with_semaphore(q) for q in queries],
        return_exceptions=True
    )

    # Convert exceptions to error results
    processed_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            processed_results.append(ResearchResult(
                rq_id=queries[i].rq_id,
                status="ERROR",
                query_text=queries[i].prompt_text,
                response_text="",
                error_message=str(result)
            ))
        else:
            processed_results.append(result)

    # Compute stats
    successful = sum(1 for r in processed_results if r.status == "SUCCESS")
    failed = len(processed_results) - successful
    total_time = (datetime.now() - start_time).total_seconds()

    logger.info(f"Completed: {successful}/{len(processed_results)} successful in {total_time:.1f}s")

    return ResearchPlanResults(
        ticker=ticker,
        execution_timestamp=datetime.now().isoformat(),
        total_queries=len(processed_results),
        successful_queries=successful,
        failed_queries=failed,
        results=processed_results,
        execution_time_seconds=total_time
    )


def save_results(results: ResearchPlanResults, output_dir: str) -> str:
    """
    Save research results to JSON file.

    Args:
        results: The ResearchPlanResults object
        output_dir: Directory to save results

    Returns:
        Path to saved file
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    filename = f"A9_RESEARCH_RESULTS_{results.ticker}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    filepath = output_path / filename

    with open(filepath, 'w') as f:
        json.dump(results.to_dict(), f, indent=2)

    logger.info(f"Results saved to {filepath}")
    return str(filepath)


# ============================================================================
# STANDALONE EXECUTION
# ============================================================================

async def main():
    """Test execution with sample research plan."""

    # Sample A.8 for testing
    sample_plan = {
        "A.8_RESEARCH_STRATEGY_MAP": {
            "schema_version": "G3_2.2.2",
            "Research_Plan": [
                {
                    "RQ_ID": "RQ1",
                    "Allocation_Type": "MANDATORY",
                    "Coverage_Objective": "M-1",
                    "Platform": "GDR",
                    "Platform_Rationale": "Test query",
                    "A7_Linkage": "Test",
                    "Prompt_Text": "What are the key financial metrics for Dave Inc (NASDAQ:DAVE) as of December 2024?"
                }
            ]
        }
    }

    results = await execute_research_plan(
        research_plan=sample_plan["A.8_RESEARCH_STRATEGY_MAP"],
        ticker="DAVE",
        max_concurrent=1,
        use_cli=True
    )

    print(json.dumps(results.to_dict(), indent=2))


if __name__ == "__main__":
    asyncio.run(main())
